{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/well/rittscher/users/achatrian/.conda/envs/pyenvclone/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numbers\n",
    "import random\n",
    "import json\n",
    "from itertools import chain\n",
    "print(sys.executable)\n",
    "sys.path.extend(['..', '../..'])\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from skimage import transform, color\n",
    "import cv2\n",
    "import imageio\n",
    "from quant.experiment.clustering import Clustering\n",
    "from base.datasets.wsi_reader import WSIReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Clustering('guassians',\n",
    "              ('StandardScaler', 'PCA', 'GaussianMixture'),\n",
    "              (StandardScaler(), PCA(n_components=5), GaussianMixture(n_components=5)),\n",
    "              caching_path='/well/rittscher/users/achatrian/pipeline_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:07<02:13,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 103230105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:13<02:02,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 167556857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:18<01:46,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 186439757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:26<01:51,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 336649387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:33<01:40,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 379079200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:38<01:28,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 397222717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:44<01:20,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 420541954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:49<01:12,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 433964695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:55<01:04,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 439822955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:01<00:58,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 449605643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:10<01:00,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 563357754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:18<00:56,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 632291849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:24<00:48,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 640652631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:31<00:42,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 685868936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:40<00:37,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 760547417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:48<00:30,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 808380014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:58<00:24,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 921108655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:06<00:16,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 981169722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:16<00:08,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 1077062791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:23<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 1100381981\n",
      "20 feature files were loaded.\n"
     ]
    }
   ],
   "source": [
    "remove_outliers = False\n",
    "e.read_data_from_dir('/well/rittscher/projects/prostate-gland-phenotyping/WSI/data/features', max_memory_use=1e10)\n",
    "if remove_outliers:\n",
    "    e.remove_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num points \", len(e.x))\n",
    "print(\"Num fields \", len(e.x.columns))\n",
    "print(e.x.index.levels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.plot_clusters()#colors=list(str(i * 0.1) for i in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file\n",
    "label_file = '/well/rittscher/projects/prostate-gland-phenotyping/WSI/data/other/TA206_Scores_V2_190718.csv'\n",
    "labels = pd.read_csv(label_file, sep='\\t')\n",
    "labels = labels.set_index('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erg = labels['ERG H Score'].apply(lambda x: int(x) if x.isdigit() else 0)\n",
    "erg = erg.apply(lambda x: int(x) > 0)\n",
    "erg = erg.iloc[0::2]  # remove benign samples from spreadseet\n",
    "erg.index = [s[:-5] for s in erg.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.x.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erg.loc[e.x.index.levels[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature space against ERG:\n",
    "colors = ['r', 'b']\n",
    "for slide, erg_v in erg.iteritems():  # erg is a Series\n",
    "    color_ = colors[int(erg_v)]\n",
    "    try:\n",
    "        slide_x = e.x.loc[slide]\n",
    "        plt.scatter(slide_x.iloc[:, 0], slide_x.iloc[:, 1], color=color_)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTEN\n",
    "pten = labels['PTEN H Score RESCORE BETTER STAINED TMA'].apply(lambda x: int(x) if x.isdigit() else 0)\n",
    "pten = pten.apply(lambda x: int(x) > 0)\n",
    "pten = pten.iloc[0::2]  # remove benign samples from spreadseet\n",
    "pten.index = [s[:-5] for s in pten.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature space against ERG:\n",
    "colors = ['r', 'b']\n",
    "for slide, pten_v in pten.iteritems():  # erg is a Series\n",
    "    color_ = colors[int(pten_v)]\n",
    "    try:\n",
    "        slide_x = e.x.loc[slide]\n",
    "        plt.scatter(slide_x.iloc[:, 0], slide_x.iloc[:, 1], color=color_)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pi\n",
    "# PTEN\n",
    "proliferation = labels['Proliferation index Mib-1 0-100% (only invasive tumour scored, not PIN or intraductal Ca or inflammatory cells. In the benign, only luminal ep cells scored)'].apply(lambda x: int(x) if x.isdigit() else 0)\n",
    "proliferation = proliferation.iloc[0::2]  # remove benign samples from spreadseet\n",
    "proliferation.index = [s[:-5] for s in proliferation.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature space against ERG:\n",
    "colors = ['r', 'b', 'g', 'y']\n",
    "for slide, pten_v in pten.iteritems():  # erg is a Series\n",
    "    color_ = colors[int(pten_v)]\n",
    "    try:\n",
    "        slide_x = e.x.loc[slide]\n",
    "        plt.scatter(slide_x.iloc[:, 0], slide_x.iloc[:, 1], color=color_)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gland examples manually ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(self, data_dir=None, n_examples=5, mpp=0.2):\n",
    "    r\"\"\"This methods assumes that the dataframe's index corresponds to the bounding box of tissue elements\n",
    "    :param n_examples: how many image examples to extract for image per cluster\n",
    "    :param mpp:\n",
    "    \"\"\"\n",
    "    if self.x is None or self.y is None:\n",
    "        raise ValueError(\"Data has not been read / processed yet for cluster extraction\")\n",
    "    if data_dir is None:\n",
    "        data_dir = Path(self.loaded_paths[0]).parents[2]\n",
    "        assert (data_dir/'data').is_dir(), \"data_dir should contain dir 'data'\"\n",
    "    self.clusters = np.unique(self.y)\n",
    "    examples = []\n",
    "    for i, cluster in enumerate(tqdm_notebook(self.clusters, desc='clusters')):\n",
    "        x_cluster = self.x.iloc[(self.y == cluster).to_numpy().squeeze()]\n",
    "        examples.append(dict())\n",
    "        for subset_id in tqdm_notebook(self.x.index.levels[0], desc='subsets'):\n",
    "            try:\n",
    "                subset_path = next((data_dir/(subset_id + sfx)) for sfx in ['.ndpi', '.svs', '.dzi'])\n",
    "            except StopIteration:\n",
    "                raise ValueError(f\"Data dir does not contain image for {subset_id}\")\n",
    "            examples[i][subset_id] = []\n",
    "            opt = WSIReader.get_reader_options(include_path=False)\n",
    "            reader = WSIReader(opt, subset_path)\n",
    "            try:\n",
    "                x_subset = x_cluster.loc[subset_id]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            sample = x_subset.sample(n=n_examples, replace=True)\n",
    "            for bb_s, row in sample.iterrows():\n",
    "                x, y, w, h = tuple(int(d) for d in bb_s.split('_'))\n",
    "                image = np.array(reader.read_region((x, y), 0, (w, h)))  # changed level from None to 0 !!!\n",
    "                if image.shape[2] == 4:  # assume 4 channels images are RGBA\n",
    "                    image = color.rgba2rgb(image)\n",
    "                if image.max() <= 1.0 and image.min() >= 0.0:\n",
    "                    image = image * 255.0\n",
    "                image = image.astype(np.uint8)\n",
    "                examples[i][subset_id].append(image)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = get_examples(e, n_examples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_examples_grid(self, save_dir, examples, image_size=512):\n",
    "    r\"\"\"\"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    n_clusters = len(examples)\n",
    "    n_subsets = len(examples[0])\n",
    "    n_examples = len(next(iter(examples[0].values())))\n",
    "    print(f\"n subsets, clusters: {n_subsets}, {n_clusters}\")\n",
    "    for n in tqdm_notebook(range(n_examples)):\n",
    "        grid = np.zeros((image_size * n_subsets, image_size * n_clusters, 3))\n",
    "        if n == 0:\n",
    "            print(f\"Grid size: {grid.size}\")\n",
    "        for j, cluster_examples in enumerate(examples):\n",
    "            for i, (subset_id, subset_examples) in enumerate(cluster_examples.items()):\n",
    "                if len(subset_examples) >= n+1:\n",
    "                    example = np.array(subset_examples[n])\n",
    "                    max_dim = max(example.shape[:2])\n",
    "                    padded = np.pad(example, (\n",
    "                            (0, max(0, max_dim - example.shape[0])),\n",
    "                            (0, max(0, max_dim - example.shape[1])),\n",
    "                            (0, 0)\n",
    "                        ), 'constant')\n",
    "                    resized = transform.resize(padded, output_shape=(image_size,)*2)\n",
    "                    resized = (resized * 255.0).astype(np.uint8)\n",
    "                    grid[i*image_size:(i+1)*image_size, j*image_size:(j+1)*image_size] = resized\n",
    "                    cv2.putText(grid, f'{j}', (j*image_size, i*image_size), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,)*3)\n",
    "                else:\n",
    "                    print(f\"No examples for cluster {j} in slide {subset_id}\")\n",
    "                    cv2.putText(grid, 'NA', (j*image_size, i*image_size), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,)*3)\n",
    "        if n_subsets > n_clusters * 2:\n",
    "            first_half, second_half = grid[:image_size*n_subsets//2], grid[image_size*n_subsets//2:]\n",
    "            grid = np.concatenate((first_half, second_half), axis=1)\n",
    "        if n_clusters > n_subsets * 2:\n",
    "            first_half, second_half = grid[:, :image_size*n_clusters//2], grid[:, image_size*n_clusters//2:]\n",
    "            grid = np.concatenate((first_half, second_half), axis=1)\n",
    "        imageio.imwrite(save_dir/f'grid{n}.png', grid)\n",
    "    with open(save_dir/'details.json', 'w') as details:\n",
    "        json.dump({\n",
    "            'experiment_name': self.name,\n",
    "            'files': list(examples[0].keys()),\n",
    "        }, details)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_examples_grid(e, '/well/rittscher/users/achatrian/temp', examples, image_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
